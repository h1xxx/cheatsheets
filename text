print
=====

# show only lines longer than 80 chars
grep '^.\{80\}' file.txt
---
perl -nle 'print if length$_>80' file.txt
---
awk 'length($0)>80' file.txt
---
sed -n '/.\{80\}/p' file.txt

# show null characters in a text file (in vim: ^@)
grep -a '\000' file.txt

# print only 3rd column with columns separated with ':'
awk -F':' '{print $3}' file.txt

# print with swapped columns in a file
awk -F':' '{print $2 ":" $1}' file.txt

# print first 20 lines
head -20 file1.txt

# print all but last 20 lines
head -n -20 file1.txt

# show lines with words BSD or linux
egrep "(BSD|linux)" file.txt

# show lines with 3-letter words starting with 't' and ending with 'e'
grep "t.e"

# show non-empty lines (\s matches any whitespace char)
sed '/^\s*$/d' file.txt

# diff on unsorted files (bash only)
diff <(sort text2) <(sort text1)

# show diff in git format
git --no-pager diff --no-index <file1> <file2>

# skip first line in a file
tail -n +2 file.txt

# print first 6 characters from third column
awk '{ print substr($3,1,6) }'

# print last 2 characters from third column
awk '{ print substr($3,length($0)-1,2) }'

# print first and last column
awk '{ print $1, $NF }'

# print lines between lines containing two strings
sed -n '/string1/,/string2/p'

# print lines between lines containing two strings; exclude first and last line
sed -n '/string1/,/string2/{/string1/b;/string2/b;p}'

# show lines only with numbers
grep '^[[:digit:]]*$' file1.txt

# show lines with non-ascii characters
LC_ALL=C grep '[^ -~]' file1.txt

# show lines with only ascii characters
LC_ALL=C grep -v '[^ -~]' file1.txt

# print line lengths
awk '{print length}' file1.txt

# reverse order of characters in each line
rev
---
sed '/\n/!G;s/\(.\)\(.*\n\)/&\2\1/;//D;s/.//'



remove
======

# remove lines containing a specific string
sed '/string123/d' filename.txt

# remove lines not containing a specific string
sed '/string123/!d' filename.txt

# remove lines containing a specific string, except for the first line
sed '0,/string123/!{//d}' filename.txt

# remove lines with a single char
sed '/^.$/d' file1



replace
=======

# capitalize first letter on each line
sed 's/./\u&/' file.txt

# remove 2 or 3 digits at the beginning of the string
sed 's|^[0-9]\{2,3\}||g' file.txt

# replace all characters to lowercase
sed -e 's|\(.*\)|\L\1|' file.txt

# replace all characters to uppercase
sed -e 's|\(.*\)|\U\1|' file.txt

# replace all characters up to first occurence of a tab character
sed 's|[^\t]*|custom\t|' file.txt

# uppercase first character in each line
sed 's/.*/\u&/' file.txt

# lowercase first character in each line
sed 's/.*/\l&/' file.txt

# replace an optional character "#" and two strings (logical or)
sed -E -e 's|<#?(magnet\|uploaded)>||g'

# insert a character on a specific position
sed 's|.|&a|16' file.txt

# add a character to every character in first column
awk '{gsub(//, "_", $1)}1' file.txt

# replace newlines with null (zero) delimiter
tr '\n' '\0'



merge
=====

# join with keeping all columns from first file
join -t':' -a1 file1 file2

# join with keeping only unmatched rows from first file
join -t':' -v1 file1 file2

# select output columns when joining files
join -o '0,1.1,2.2' file1 file 2
# 0	the key field
# 1.1	the first field of first file
# 2.2	the second field of the second file

# combine already sorted files
sort -m file1 file2

# merge by columns
sort -T ./ -o tmp1 -t':' -k2,2 linkedin_email_sha1.txt
sort -o tmp2 -t':' -k1,1 linkedin_sha1_pass.txt
join -t':' -a1 -1 2 -2 1 tmp1 tmp2 > tmp
awk -F':' '{print $2 "\t" $3}' tmp > final

# cartesian product of lines; each line merged with each line from other file
join -j 2 file1 file2
---
awk '(NR==FNR) { a[NR]=$0 } (NR != FNR) { for (i in a) { print $0 a[i] } }' file2 file1



misc
====

# justify text - limit each paragraph to 72 chars
fmt -w 72 file.txt
---
fold -w 72 file.txt

# custom date format
date +%Y-%m-%d_%H:%M:%S

# convert epoch to date format
date -d '@1600000000'

# convert date to other format (like epoch in this case)
date -d "2016-04-03 14:22:59" +%s

# get a date element (minutes) without padding of 0 (single digit)
date -d "2016-04-03 14:02:59" +%-M

# add/subtract days from a date
date -d '-180 days'
---
today=$(date +%Y%m%d)
yesterday="$(date -d "$today - 1 days" +%Y%m%d)"

# get previous day
date -d '-1 days' +%Y-%m-%d

# keep only first line occurence of a column/field combination
awk '!seen[$1,$2,$3]++' file.txt
---
awk -F'\t' '!seen[$1 FS $3 FS $4 FS $5 FS $6 FS $7]++' file.txt

# check if file is sorted
sort -c file1.txt

# convert txt to pdf
libreoffice --convert-to "pdf" file.txt



tr
==

# delete a new line from a string
tr -d '\n' string

# convert string to lowercase
echo "Sample Text" | tr '[:upper:]' '[:lower:]'

# convert multiple chars, a to x, b to y, c to z
echo abc | tr 'abc' 'xyz'

# remove all non printable characters from a file
cat file1.txt | tr -cd "[:print:]\n"

# squeeze mutliple spaces into one
tr -s ' '

# rotate (shift) each letter by 13 decimal digits; ROT13
cat file1.txt | tr '[a-zA-Z]' '[n-za-mN-ZA-M]'

# rotate (shift) each letter by 1 decimal digit
cat file1.txt | tr '[a-zA-Z]' '[b-zaB-ZA]'

# count the occurences of a character (x)
tr -cd x < file.txt | wc -c

# count the number of specific characters ('x') in each line
tr -d -c 'x\n' < input.txt | awk '{ print length; }'

# repeat a character n times
printf '%80s\n' | tr " " "="

# change lowercase to uppercase
tr 'a-z' 'A-Z'
---
tr '[:lower:]' '[:upper:]'

# change lowercase/uppercase also for non-ascii utf-8 chars
LC_ALL=en_US.utf8 awk '{print tolower($0)}' file.txt
---
LC_ALL=en_US.utf8 awk '{print toupper($0)}' file.txt



awk
===

# print third to last columns
awk '{for(i=3;i<=NF;++i)print $i}'

# print lines with number in first and third column greater than 7 and 8
awk '$1 > 7 && $3 > 8'

# print lines between empty lines containing string1
awk '/string1/{printf $0 RS}' RS='\n\n' file1.txt

# lowercase characters only in first column
awk -F' ' '{l = $0; sub($1, "", l); print tolower($1) l}' file1.txt

# calculate avarage from a space separated list of numbers
awk '{s += $1} END {print "avg:", s/NR}' RS=' ' file1.txt

# modify two columns in-place
awk -i inplace '{ $1 = "text1"; $2 = "text2"; print }' file1.txt

# count the number of specific characters ('x') in each line
awk -F x '{print NF-1}' input.txt

# print specific lines (3-5), quit processing on 6th line
awk 'NR>=3{print}NR==5{exit}' input.txt

# sum a list of numbers
awk '{ sum += $1 } END { print sum }' file

# add a string to stdin
echo '64 - 44' | awk -F'\t' '{print "(" $1 ") / 10"}' | bc

# use a variable from shell
awk -v sum="${sum}" '{print 100/sum}'

# use formatted string in each row
awk '{printf "%s %8s\n",$1,$2}'

# merge two unsorted files based on first column
awk -F: 'FNR==NR{a[$1]=$0;next}{if($1 in a){print a[$1];} else {print;}}' file2 file1

# print text between two strings
awk -v FS="(string1|string2)" '{print $2}'

# print double quotes \x22 in ascii
awk '{print "\x22" $2 "\x22 " $1}'

# change output field separator
awk -F'\t' -v OFS='\t' '{print $7, $1, $2, $3, $4, $5}'

# print all but first column
awk '{$1=""; print $0}' somefile

# print all but two first columns
awk '{$1=$2=""; print $0}' somefile

# find lines missing in another file - not sorted data
awk 'NR==FNR{a[$0]=1;next}!a[$0]' file1 file2

# calculate a sum of a column
awk '{sum+=$2} END {print sum/1024}' file.txt



sed
===

# print one line from a text file
sed -n '99p' file.txt

# print a few specific lines from a text file
sed -n -e 99p -e 100p file.txt

# print all between specific lines from a text file
sed -n '97,120p' file.txt

# delete a string from the beginning
sed 's#^string/##'

# delete lines containing str1 and str2
sed '/str1\|str2/d' file

# delete lines not containing str1 and str2
sed '/str1\|str2/!d' file

# delete lines containing str1 using non-slash delimiter
sed '\|str1|d' file

# delete empty lines
sed '/^\s\*$/d'

# delete all non alphanumeric and non ascii characters
sed 's/[^a-zA-Z0-9]//g'

# delete all non alphanumeric characters using class
sed 's/[^[:alnum:]]//g'

# delete a string after specific character (=)
sed 's/=.*//'

# delete a string after specific set of characters (=!)
sed 's/[=!].*//'

# delete a string before a specific string ('magnet:')
sed 's/.*magnet:/magnet:/'

# delete non-ascii characters
sed 's/[\128-\255]//g' file1.txt
---

# delete non-printable characters
sed 's/[^[:print:]]//' file1.txt

# delete control characters
sed 's/[[:cntrl:]]//g' file1

# split each character to a separate line
sed 's|\(.\)|\1\n|g' file1.txt

# replace string only in lines containing a pattern
sed '/search_pattern/ s/old_val/new_val/'

# replace strings only after a colon
sed '/^search_value:/ s/:.*/: new_val/'

# replace a string on a specific line (4)
sed -e "4s/bike/car/"

# replace a string containing newline (multiline string)
sed -z 's|line1\nline2|xxx|g'

# add text in a first line
sed -i '1s/^/<added text> /' file

# add text in a first 10 lines
sed -i '1,10s/^/<added text> /' file

# replace optional character
sed 's|https\{0,1\}://.*|http://example.com|g' file

# add a colon character every other two characters
sed 's/../&:/g' file1.txt
---
sed 's/.\{2\}/&:/g' file1.txt

# use ascii hex values in sed expression
echo abcdef | sed 's/[\x63-\x6f]/z/g'
---
echo abcdef | sed 's/[^\x63-\x6f]/z/g'

# replace a string in all files containging the string
grep -rl string path/*.py | xargs sed -i 's/string/new_string/g'

# replace multiple lines with one word
sed ':a;N;$!ba;s/START.*END/SINGLEWORD/g' filename
---
perl -i -p0e 's/START_STR.*?END_STR/SINGLEWORD/s' file

# print a line
sed -ne '/^str1/p' somefile

# print multiple lines
sed -ne '/^str1/p' -e '/^str2/p' somefile

# print specific lines (3-5), quit processing on 6th line
sed -n '3,5p;6q' input.txt

# print all lines after a match
sed -n '/^somematch/,$p' filename

# count the number of specific characters ('x') in each line
sed 's/[^x]//g' input.txt | awk '{ print length }'

# sed character classes
[[:alnum:]]     [:alpha:] and [:digit:], same as [0-9A-Za-z]
[[:alpha:]]     alphabetic chars: [:lower:] and [:upper:], same as [A-Za-z]
[[:blank:]]     blank chars: space and tab
[[:cntrl:]]     control characters: octal 000-037, and 177 (DEL)
[[:digit:]]     digits chars
[[:graph:]]     graphical chars: [:alnum:] and [:punct:]
[[:lower:]]     lower-case letters
[[:print:]]     printable chars: ‘[:alnum:]’, ‘[:punct:]’, and space
[[:punct:]]     punctuation chars:
                ! " # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \ ] ^ _ ` { | } ~
[[:space:]]     space chars: \t, \n, \v, \f, \r, and space
[[:upper:]]     upper-case letters
[[:xdigit:]]    hexadecimal digits: 0 1 2 3 4 5 6 7 8 9 A B C D E F a b c d e f



cut
===

# print last two columns
cat file.txt | rev | cut -d'.' -f1,2 | rev

# print first character from each line
cut -b 1 file.txt

# select specific characters
cut -c 2,3 file.txt

# revove last character
echo abc | rev | cut -c 2- | rev

# cut with tab delimiter (ctrl+v and then tab to make a tab char)
cut -d' ' -f1



sort
====

# parameters' list
-n	sort by a number from first column
-h	sort by a human readable number from first column
-r	reverse the results
-u	get only unique lines
-c	count occurences of unique lines

# sort a file inplace
sort -o file file

# sort a realy large file
LC_ALL=C sort -u -T. -S 60G --parallel=16 file1

# get only unique lines from a sorted file with the count of occurences
uniq -c

# sort by first column with defined delimeter
sort -u -k1,1 -t':' file.txt > file.out

# sort by line length
cat file.txt | awk '{ print length, $0 }' | sort -n | cut -d" " -f2-

# unique sort only based only on frist 3 columns (keep first occurence)
sort -u -k1,1 -k2,2 -k3,3 file1.txt



misc
====

# generate a sequence of numbers from 1 to 255 separated by new line
seq 255

# generate a sequence of numbers from 1 to 255 separated by new line
seq 0 255

# equal width mode
seq -w 0001 0003

# format string
seq -f %04g 0 3

# find lines with ip addresses
grep -E -o "([0-9]{1,3}[\.]){3}[0-9]{1,3}"

# remove lines that are in file2 from file1
grep -Fvxf <file2> <file1>

# join every two lines
paste - - < input.txt

# list all files separated by coma in one line
ls -1 | paste -sd " " -

# sum numbers in a list (one number per line)
paste -sd+ <input file> | bc

# show differences in two columns
diff -y -W 160 <file1> <file2>

# print hex value in binary format
printf '\x54'
echo -ne '\x2593'

# convert hex string to ascii
echo 5a5a5a |  xxd -r -p

# print unicode character in binary format
printf '\u2593'
---
echo -ne '\u2593'

# add a colon character every other two characters
echo 'f5dcc404943eba32' | fold -w2 | paste -sd':' -

# randomize lines in a file
shuf file1

# calculate avarage from a space separated list of numbers
seq 10 | jq -s add/length

# find lines only in file1
comm -23 file1 file2

# find lines only in file2
comm -13 file1 file2

# find lines common to both files
comm -12 file1 file2

# insert text at the beginning of the file
{ echo -n 'new line'; cat file1; } > file2

# convert decimal to hex
printf "%x\n" 21

# slit file into 3 chunks without splitting lines
split -n l/3 file1.txt

# slit file into chunks each with 1000 lines
split -l 1000 file1.txt

# print repeated character
head -c 100000 /dev/zero | tr '\0' '.'

# convert tabs to spaces with 14 space width
expand --tabs=14 file1

# print hex value in decimal
printf "%d\n" 0x3a

# pipe output from an awful info utility to less
info --subnodes -o - "$@" | less

# create large ascii signs
figlet -c -f big 1x "" 2y "" 3z

# ascii separators for text files
1c  FS  ^\  File Separator
1d  GS  ^]  Group Separator
1e  RS  ^^  Record Separator
1f  US  ^_  Unit Separator

# print only unique lines without sorting
awk '!x[$0]++' file1.txt
---
cat -n file_name | sort -uk2 | sort -n | cut -f2-

# use tab as line separator in awk
awk -F '\t' file1.txt

# calculate hash for each line of text (fast)
perl -MDigest::MD5 -nle 'print Digest::MD5::md5_hex($_), ":", $_' < file.in >> file.out
---
perl -MDigest::SHA -nle 'print Digest::SHA::sha256_hex($_), ":", $_' < file.in >> file.out



jq
==

# parameters' list
-M	disable colors (monochrome)
-r	don't format output as json (raw)

# select results based on keys
jq '[.[] | select(.key1=="val1" or .key2!=val2)]' file1.json

# select specific keys
jq '{key1,key2}' file1.json
---
jq '.[] | .key1, .key2, "<empty line>" ' file1.json

# parse jsonl file
jq -c '.[]'

# remove null values
jq '.[] | del(..|nulls)'

# print only values as tsv
jq  -r '[.key1, .key2]|@tsv'



xml
===

# view xml document
xmlstarlet ed <xml file>

# select a field from xml document
xmlstarlet sel -t -v //office:text <xml file>

# prettify xml document
xmllint --format file1.xml

# compare two xml files
xmllint --format 1.xml | xmllint --exc-c14n - > x
xmllint --format 2.xml | xmllint --exc-c14n - > y
vimdiff x y



encoding
========

# iconv parameters' list
-c	continue on errors in conversion

# remove any non utf-8 characters
iconv -f utf-8 -t utf-8 -c

# convert from unicode to ascii, ignore errors in conversion
iconv -c -f utf-8 -t us-ascii//translit file1.txt

# delete null characters from a text file
sed 's/\x0//g' file.txt
---
tr < file.txt -d '\000' > cleanfile

# delete windows cariage return characters from a text file (in vim: ^M)
dos2unix file.txt > file.out
---
tr < file.txt -d '\r' > file.out
---
awk -v RS='\r\n' '{print ,}' file.txt > file.out

