sqlite3
=======

# sqlite commands' list
.tables				show tables
.schema				show schemas
pragma table_info(mytbl);	show fields in the table
pragma integrity_check;		check if the database is healthy
vacuum;				defragment a database
vacuum into db2.sqlite;		backup defragmented databse in another file

# config commands' list
.show			show current config
.header on		turn on headers
.output file.txt	send output to a file
.output stdout		send output to stdout
.width 5 15 5 20	change widtch of consecutive columns
.mode column		table format
.mode line		each value in a separate line
.mode list		default
.mode insert		sql insert queries format
.mode html		html format
.mode csv		csv format
.mode tabs		tsv format
.mode tcl		non ascii values are escaped, columns are qouted

# read a database from a file
sqlite3 db1.sqlite

# show tables in a database
sqlite> .tables

# show column/field names in a table
sqlite> PRAGMA table_info(table1);

# dump database to csv - oneliner
sqlite3 -header -csv db1.sqlite "select * from table1;" > table1.csv

# dump database to csv - oneliner with query from a file
sqlite3 -header -csv db1.sqlite < query.sql > table1.csv

# run sql query for the database
sqlite3 file.db < file.sql

# run a query from command line
echo ".mode line\n select * from table1;" | sqlite3 db.sqlite

# repair a broken databse
echo '.dump' | sqlite3 db.sqlite | sqlite3 db_repaired.sqlite

# open database in read-only mode
sqlite3 -cmd ".timeout 5000" "file:/path/mydb.sqlite3?mode=ro&immutable=1"

# view the blob (binary) column as ascii
sqlite> select hex(bob_col) from table1;



sqlite3 common queries
======================

# select records matching a case sensitive pattern ("binary")
SELECT * FROM tbl1 WHERE column1 like binary "%xxx%"

# select records and sleep for 1 second (useful for blind sql injection)
SELECT * FROM tbl1 and sleep(1)

# aggregate data
SELECT department_name, ROUND(AVG(salary), 0) as avg_salary,
	avg_salary / ( select sum(salary) from employees) as crazy_perc
FROM employees
GROUP by department_name
ORDER by avg_salary DESC

# select time column expressend in seconds
SELECT DATE(ROUND(modified_on), 'unixepoch') AS isodate from torrents limit 10;
---
SELECT DATETIME(ROUND(modified_on), 'unixepoch') AS isodate from torrents;

# select top IDs
select * from table 1 ORDER BY id DESC limit 10;

# select count of most frequent values in a column
SELECT col1, count(col1) AS count FROM t1 GROUP BY col1 ORDER BY count DESC;

# make sure that null values are unique by creating an index
CREATE UNIQUE INDEX ix ON table1 (col1, col2);

# get last record
SELECT id,value FROM my_table ORDER BY id DESC LIMIT 1;

# pattern matching
SELECT * FROM table1 WHERE imdb GLOB 'tt*[1-9][1-9][1-9][1-9][1-9][1-9]??';

# write a binary blob to a file
select writefile('blob.bin', blob_column) from table where key= '12345';
---
sqlite3 file.db "select hex(bmp) from reg where id=1" | xxd -r -p > 2.png



sqlite3 sessions examples
=========================

# dump database to csv from sqlite interpreter
sqlite> .headers on
sqlite> .mode csv
sqlite> .output data.csv
sqlite> SELECT * from table1;
sqlite> .quit

# make a join of two csv files
sqlite> .mode csv
sqlite> .header on
sqlite> .import weight.csv weight
sqlite> .import person.csv person
sqlite> select * from person, weight where person.ID = weight.ID;

# select same records from two databases
sqlite> attach 'database.sqlite3.1' as db1;
sqlite> attach 'database.sqlite3.2' as db2;
sqlite> SELECT * from db1.table a inner join db2.table b where a.name = b.name;

# merge tables from two databases (IDs might get duplicated)
sqlite> attach 'c:\test\b.db3' as toMerge;
sqlite> BEGIN;
sqlite> insert into AuditRecords select * from toMerge.AuditRecords;
sqlite> COMMIT;
sqlite> detach toMerge;

# merge two databases with unique records
sqlite3 db1.sqlite3 .dump | sqlite db3.sqlite3
sqlite3 db2.sqlite3 .dump | sqlite db3.sqlite3

# read csv file
sqlite> create table foo(a, b);
sqlite> .separator ,
sqlite> .import test.csv foo



python
======

# open a connection to the database
conn = sqlite3.connect('database.db')
cursor = conn.cursor()
...
cursor.close()
conn.close()

# read data from csv into memory
df = pandas.read_csv('data.csv')
conn = sqlite3.connect(":memory:")
df.to_sql("table_name", conn, index=False)
cursor = conn.cursor()

# list tables in a database
cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
print(cursor.fetchall())

# make a query and use for loop to iterate
res = cursor.execute("SELECT * FROM sqlite_master;")
for name in res:
    print(name)

# list fields in a table
res = cursor.execute("SELECT * FROM table_name;")
col_names = [ col[0] for col in res.description ]

# export sqlite database to csv
import sqlite3
import csv
inpsql3 = sqlite3.connect('input.sql3')
sql3_cursor = inpsql3.cursor()
sql3_cursor.execute('SELECT * FROM clients')
with open('output.csv','w', newline='') as out_csv_file:
    csv_out = csv.writer(out_csv_file)
    # write header
    csv_out.writerow([d[0] for d in sql3_cursor.description])
    # write data
    for result in sql3_cursor:
        csv_out.writerow(result)
inpsql3.close()



mongo
=====

# example mongo cli session
mongo --port 27117 ||  mongosh 10.129.81.210
show dbs
db.version()
use users
show collections
db.coll_123.find().pretty()


# change a value (password in this case)
mkpasswd -m sha-512 Password1234
...
use ace
db.admin.find().pretty()
db.admin.update({"_id": ObjectId("61ce278f46e0fb0012d47ee4")},{$set:{"x_shadow":"GENERATED SHA_512 HASH"}})
db.admin.update({"_id": ObjectId("61ce278f46e0fb0012d47ee4")},{$set:{"x_shadow":"$6$ddLG.x4jlRs5ws12$cAYHPcvVnlJ3O0TQPCf0IbUNH2Spd6idNWNCkfM/sSuek23tqIpAEgFdnfn6EbIsPqqXDwhPDqSX1e5N8NmLO."}})

redis
=====

# example redis-cli session
redis-cli -s /run/redis.sock
keys *
select 1
keys *
get temp
info memory
info
select 0
keys *

