arrays/slices
=============

# create and initialize a slice
slice1 = []string{"1.el", "2.el"}
---
x := []int{2, 7, 11, 15}

# concatenate (merge) two slices
slice3 = append(slice1,slice2...)

# empty/clear a slice
slice = nil

# convert slice to array
var hashArray [20]byte
copy(hashArray[:], hashSlice)

# copy a slice
src := []int{1, 2, 3, 4, 5}
dst := make([]int, len(src))
copy(dst, src)

# get min/max value from integers
min(2, -5, 8, 1.2)
max(2, -5, 8, 1.2)

# get min/max value from floats
x := []float64{2, -5, 8, 1.2}
slices.Min(x)
slices.Max(x)



maps
====

# initialize a map
map1 = map[string]string{}
---
map1 = make(map[string]string)

# initialize a map with size pre-allocated
map1 = make(map[string]string, 32768)

# initialize nested map
var x = map[string]map[string]string{}
x["map1"] = map[string]string{}
x["map2"] = map[string]string{}

# create and initialize a map
counts := map[string]int {
	"c1": 3711,
	"c2": 2138,
}

# check if key exists in map
val, keyExists := map1["key1"]

# remove a key from map
delete(map1, "key1")

# create a map of empty structs
map1 := make(map[string]struct{})
map1["key"] = struct{}{}

# clear a map or a slice
clear(map1)

# update a key only if it doesn't exist
if _,exists := m[key]; !exists {
    m[key]="new val"
}



structs
=======

# create and initialize a struct
person1 := Person{name: "Name", age: 69}

# clear a struct
person1 = Person{}

# modify a struct in slices of structs
(&slice[0]).key1 = "value1"

# sort and search in a slice of structs
crowd := []Person{{"Zoey"}, {"Anna"}, {"Benni"}, {"Chris"}}
sort.Slice(crowd, func(i, j int) bool {
	return crowd[i].Name <= crowd[j].Name
})
needle := "Benni"
idx := sort.Search(len(crowd), func(i int) bool {
	return string(crowd[i].Name) >= needle
})
if crowd[idx].Name == needle {
	fmt.Println("Found:", idx, crowd[idx])
} else {
	fmt.Println("Found noting: ", idx)
}



interfaces
==========

# determine interface type
var t interface{}
t = functionOfSomeType()
switch t := t.(type) {
default:
    fmt.Printf("unexpected type %T", t)       // %T prints whatever type t has
case bool:
    fmt.Printf("boolean %t\n", t)             // t has type bool
case int:
    fmt.Printf("integer %d\n", t)             // t has type int
case *bool:
    fmt.Printf("pointer to boolean %t\n", *t) // t has type *bool
case *int:
    fmt.Printf("pointer to integer %d\n", *t) // t has type *int
}

# cast interface to a variable
var1.(string)

# cast interface to a struct
struct1, ok := varIface1.(structT)



json
====

# decode json from a string into a map
import encoding/json
var result map[string]interface{}
var result []interface{}
var result []CustomStruct
json.NewDecoder(jsonString).Decode(&result)

# decode json example
import encoding/json
type findMntStruct struct {
	Filesystems  []fsStruct      `json:"filesystems"`
}
type fsStruct struct {
	Target   string      `json:"target"`
	Source   string      `json:"source"`
	Fstype   string      `json:"fstype"`
	Options  string      `json:"options"`
}
cmd := exec.Command("/bin/findmnt", "-J", "/mnt/sda")
out, err := cmd.Output()
if err == nil {
	var result findMntStruct
	err := json.Unmarshal(out, &result)
	fmt.Println(result.Filesystems[0].Source)
}

# encode string to json with pretty printing
j, err := json.MarshalIndent(ti, "", "\t")
jStr := string(j)

# ignore a field in struct
	Category string         `json:"-"`



toml
====

# parse toml list into slice
conf, err := toml.Load("example.toml")
confStep := conf.Get("section").(*toml.Tree)
iSlice := confStep.Get("item").([]interface{})
sSlice := make([]string, len(iSlice))
for i := range iSlice {
	sSlice[i] = iSlice[i].(string)
}

# check if toml file has fields
conf, err := toml.Load("example.toml")
conf.Has("example_section")
conf.HasPath([]string{"example_section", "value"})



misc
====
# find variable type
reflect.TypeOf(var1)

# read compressed csv
import (
	"compress/gzip"
	"encoding/csv"
)
fd, err := os.Open("file1.csv.gz")
errExit(err)
defer fd.Close()
gr, err := gzip.NewReader(fd)
errExit(err)
defer gr.Close()
cr := csv.NewReader(gr)
for {
	fields, err := cr.Read()
	if err == io.EOF {
		break
	}
	errExit(err)
	fmt.Println(fields)
}

# read json
type Data struct {
	Name string `json:"name"`
}
content, err := ioutil.ReadFile("./config.json")
var payload Data
err = json.Unmarshal(content, &payload)



postgres
========

# bulk insert (fastest)
import (
	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgxpool"
)
ctx := context.Background()
conn, err := pgxpool.New(ctx, cfg.String())
errExit(err)
defer conn.Close()
rows := [][]interface{}{}
for scanner.Scan() {
	rows = append(rows, []interface{}{val1, val2})
	if len(rows) > 1048576 {
		copyCount, err := conn.CopyFrom(ctx,
			pgx.Identifier{"table_1"},
			[]string{"col1", "col2"},
			pgx.CopyFromRows(rows),
		)
		errExit(err)
		rows = [][]interface{}{}
	}
}

# bulk insert (2x slow as CopyFrom)
import (
	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgxpool"
)
ctx := context.Background()
conn, err := pgxpool.New(ctx, cfg.String())
errExit(err)
defer conn.Close()
batch := &pgx.Batch{}
for scanner.Scan() {
	q := `INSERT INTO hashes (col1, col2) VALUES ($1, $2);`
	batch.Queue(q, val1, val2)
	if batch.Len() > 1048576 {
		br := conn.SendBatch(ctx, batch)
		err = br.Close()
		errExit(err)
		batch = &pgx.Batch{}
	}
}

